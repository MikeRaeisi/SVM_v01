{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Australian rain forecast using SVM algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read the csv file and show a few top rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Location</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Evaporation</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>WindGustDir</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindDir9am</th>\n",
       "      <th>...</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Pressure9am</th>\n",
       "      <th>Pressure3pm</th>\n",
       "      <th>Cloud9am</th>\n",
       "      <th>Cloud3pm</th>\n",
       "      <th>Temp9am</th>\n",
       "      <th>Temp3pm</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>RainTomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-12-01</td>\n",
       "      <td>Albury</td>\n",
       "      <td>13.4</td>\n",
       "      <td>22.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>44.0</td>\n",
       "      <td>W</td>\n",
       "      <td>...</td>\n",
       "      <td>71.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1007.7</td>\n",
       "      <td>1007.1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.9</td>\n",
       "      <td>21.8</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-12-02</td>\n",
       "      <td>Albury</td>\n",
       "      <td>7.4</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WNW</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NNW</td>\n",
       "      <td>...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1010.6</td>\n",
       "      <td>1007.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.2</td>\n",
       "      <td>24.3</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-12-03</td>\n",
       "      <td>Albury</td>\n",
       "      <td>12.9</td>\n",
       "      <td>25.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WSW</td>\n",
       "      <td>46.0</td>\n",
       "      <td>W</td>\n",
       "      <td>...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1007.6</td>\n",
       "      <td>1008.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.2</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-12-04</td>\n",
       "      <td>Albury</td>\n",
       "      <td>9.2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NE</td>\n",
       "      <td>24.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>...</td>\n",
       "      <td>45.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1017.6</td>\n",
       "      <td>1012.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.1</td>\n",
       "      <td>26.5</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-12-05</td>\n",
       "      <td>Albury</td>\n",
       "      <td>17.5</td>\n",
       "      <td>32.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>41.0</td>\n",
       "      <td>ENE</td>\n",
       "      <td>...</td>\n",
       "      <td>82.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1010.8</td>\n",
       "      <td>1006.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>29.7</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2008-12-06</td>\n",
       "      <td>Albury</td>\n",
       "      <td>14.6</td>\n",
       "      <td>29.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WNW</td>\n",
       "      <td>56.0</td>\n",
       "      <td>W</td>\n",
       "      <td>...</td>\n",
       "      <td>55.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1009.2</td>\n",
       "      <td>1005.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.6</td>\n",
       "      <td>28.9</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2008-12-07</td>\n",
       "      <td>Albury</td>\n",
       "      <td>14.3</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>50.0</td>\n",
       "      <td>SW</td>\n",
       "      <td>...</td>\n",
       "      <td>49.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1009.6</td>\n",
       "      <td>1008.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.1</td>\n",
       "      <td>24.6</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2008-12-08</td>\n",
       "      <td>Albury</td>\n",
       "      <td>7.7</td>\n",
       "      <td>26.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>35.0</td>\n",
       "      <td>SSE</td>\n",
       "      <td>...</td>\n",
       "      <td>48.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1013.4</td>\n",
       "      <td>1010.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.3</td>\n",
       "      <td>25.5</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2008-12-09</td>\n",
       "      <td>Albury</td>\n",
       "      <td>9.7</td>\n",
       "      <td>31.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NNW</td>\n",
       "      <td>80.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>...</td>\n",
       "      <td>42.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1008.9</td>\n",
       "      <td>1003.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.3</td>\n",
       "      <td>30.2</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2008-12-10</td>\n",
       "      <td>Albury</td>\n",
       "      <td>13.1</td>\n",
       "      <td>30.1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>28.0</td>\n",
       "      <td>S</td>\n",
       "      <td>...</td>\n",
       "      <td>58.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>1005.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.1</td>\n",
       "      <td>28.2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date Location  MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine  \\\n",
       "0  2008-12-01   Albury     13.4     22.9       0.6          NaN       NaN   \n",
       "1  2008-12-02   Albury      7.4     25.1       0.0          NaN       NaN   \n",
       "2  2008-12-03   Albury     12.9     25.7       0.0          NaN       NaN   \n",
       "3  2008-12-04   Albury      9.2     28.0       0.0          NaN       NaN   \n",
       "4  2008-12-05   Albury     17.5     32.3       1.0          NaN       NaN   \n",
       "5  2008-12-06   Albury     14.6     29.7       0.2          NaN       NaN   \n",
       "6  2008-12-07   Albury     14.3     25.0       0.0          NaN       NaN   \n",
       "7  2008-12-08   Albury      7.7     26.7       0.0          NaN       NaN   \n",
       "8  2008-12-09   Albury      9.7     31.9       0.0          NaN       NaN   \n",
       "9  2008-12-10   Albury     13.1     30.1       1.4          NaN       NaN   \n",
       "\n",
       "  WindGustDir  WindGustSpeed WindDir9am  ... Humidity9am  Humidity3pm  \\\n",
       "0           W           44.0          W  ...        71.0         22.0   \n",
       "1         WNW           44.0        NNW  ...        44.0         25.0   \n",
       "2         WSW           46.0          W  ...        38.0         30.0   \n",
       "3          NE           24.0         SE  ...        45.0         16.0   \n",
       "4           W           41.0        ENE  ...        82.0         33.0   \n",
       "5         WNW           56.0          W  ...        55.0         23.0   \n",
       "6           W           50.0         SW  ...        49.0         19.0   \n",
       "7           W           35.0        SSE  ...        48.0         19.0   \n",
       "8         NNW           80.0         SE  ...        42.0          9.0   \n",
       "9           W           28.0          S  ...        58.0         27.0   \n",
       "\n",
       "   Pressure9am  Pressure3pm  Cloud9am  Cloud3pm  Temp9am  Temp3pm  RainToday  \\\n",
       "0       1007.7       1007.1       8.0       NaN     16.9     21.8         No   \n",
       "1       1010.6       1007.8       NaN       NaN     17.2     24.3         No   \n",
       "2       1007.6       1008.7       NaN       2.0     21.0     23.2         No   \n",
       "3       1017.6       1012.8       NaN       NaN     18.1     26.5         No   \n",
       "4       1010.8       1006.0       7.0       8.0     17.8     29.7         No   \n",
       "5       1009.2       1005.4       NaN       NaN     20.6     28.9         No   \n",
       "6       1009.6       1008.2       1.0       NaN     18.1     24.6         No   \n",
       "7       1013.4       1010.1       NaN       NaN     16.3     25.5         No   \n",
       "8       1008.9       1003.6       NaN       NaN     18.3     30.2         No   \n",
       "9       1007.0       1005.7       NaN       NaN     20.1     28.2        Yes   \n",
       "\n",
       "   RainTomorrow  \n",
       "0            No  \n",
       "1            No  \n",
       "2            No  \n",
       "3            No  \n",
       "4            No  \n",
       "5            No  \n",
       "6            No  \n",
       "7            No  \n",
       "8           Yes  \n",
       "9            No  \n",
       "\n",
       "[10 rows x 23 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"D:\\\\1. Data\\\\OneDrive\\\\OneDrive - University of Calgary\\\\PhD\\\\Datasets\\\\Weather Australia\\\\weatherAUS.csv\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Drop Nan values in target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.dropna(axis=0,subset=['RainTomorrow'])\n",
    "# df2.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Break input data frame\n",
    "\n",
    "1- Separate X and y values\n",
    "\n",
    "2- split training, validation, and test sets with the share of 60%, 20%, and 20% respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_in = df2.copy()\n",
    "y_in = x_in.pop('RainTomorrow')\n",
    "\n",
    "x_trnval, x_tst, y_trnval, y_tst = train_test_split(x_in, y_in, test_size=0.2, shuffle=True)\n",
    "# to have the same number for validation as test, the following portion will be 0.25 (25% of the remaining 80%)\n",
    "x_trn, x_val, y_trn, y_val = train_test_split(x_trnval, y_trnval, test_size=0.25, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Date column from object data type into number data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datetime import datetime\n",
    "# datetime.strptime(x_trn.Date[0], '%Y-%m-%d')\n",
    "def date_to_days(date_in):\n",
    "    '''\n",
    "    This function get a dataseries containing a date in str format\n",
    "    Then return the number of days after year 2007 because we know that the database year start after 2007\n",
    "    '2007-02-03'=(2007-2007)*365 + dayofyear('02-03')\n",
    "    Note: we assume all years are 365 days for simplicity\n",
    "    '''\n",
    "    yrs_day = (pd.to_datetime(date_in).dt.year - 2007) * 365\n",
    "    day_num = pd.to_datetime(date_in).dt.dayofyear\n",
    "    \n",
    "    return yrs_day + day_num\n",
    "\n",
    "\n",
    "x_trn = x_trn.assign(Date=date_to_days(x_trn.Date))\n",
    "x_val = x_val.assign(Date=date_to_days(x_val.Date))\n",
    "x_tst = x_tst.assign(Date=date_to_days(x_tst.Date))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert target column into int data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No', 'Yes'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Targets are yes/no (object data type)\n",
    "y_in.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Impute nan values\n",
    "find the object and number type columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_obj = x_trn.select_dtypes('object').columns.tolist()\n",
    "col_num = x_trn.select_dtypes('number').columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Simple Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "si_obj = SimpleImputer(strategy='most_frequent')\n",
    "si_num = SimpleImputer(strategy='mean')\n",
    "\n",
    "x_trn_si = x_trn.copy()\n",
    "x_val_si = x_val.copy()\n",
    "x_tst_si = x_tst.copy()\n",
    "\n",
    "x_trn_si.loc[:,col_obj] = si_obj.fit_transform(x_trn[col_obj])\n",
    "x_trn_si.loc[:,col_num] = si_num.fit_transform(x_trn[col_num])\n",
    "\n",
    "x_val_si.loc[:,col_obj] = si_obj.transform(x_val[col_obj])\n",
    "x_val_si.loc[:,col_num] = si_num.transform(x_val[col_num])\n",
    "\n",
    "x_tst_si.loc[:,col_obj] = si_obj.transform(x_tst[col_obj])\n",
    "x_tst_si.loc[:,col_num] = si_num.transform(x_tst[col_num])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Iterative Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "ii_num = IterativeImputer(max_iter=20, tol=0.1, n_nearest_features=4, initial_strategy='mean')\n",
    "# IterativeImputer does not work with object (categorical) data types\n",
    "# !!!!! need further investigation\n",
    "ii_obj = SimpleImputer(strategy='most_frequent') # IterativeImputer(max_iter=20, tol=1, n_nearest_features=5, initial_strategy='most_frequent')\n",
    "\n",
    "x_trn_ii = x_trn.copy()\n",
    "x_val_ii = x_val.copy()\n",
    "x_tst_ii = x_tst.copy()\n",
    "\n",
    "x_trn_ii.loc[:,col_num] = ii_num.fit_transform(x_trn[col_num])\n",
    "x_trn_ii.loc[:,col_obj] = ii_obj.fit_transform(x_trn[col_obj])\n",
    "\n",
    "x_val_ii.loc[:,col_num] = ii_num.transform(x_val[col_num])\n",
    "x_val_ii.loc[:,col_obj] = ii_obj.transform(x_val[col_obj])\n",
    "\n",
    "x_tst_ii.loc[:,col_num] = ii_num.transform(x_tst[col_num])\n",
    "x_tst_ii.loc[:,col_obj] = ii_obj.transform(x_tst[col_obj])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. KNN Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "ki_num = KNNImputer(n_neighbors=5, weights='uniform')\n",
    "# KNNImputer does not work with object (categorical) data types\n",
    "# !!!!! need further investigation\n",
    "ki_obj = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "x_trn_ki = x_trn.copy()\n",
    "x_val_ki = x_val.copy()\n",
    "x_tst_ki = x_tst.copy()\n",
    "\n",
    "x_trn_ki.loc[:,col_num] = ki_num.fit_transform(x_trn[col_num])\n",
    "x_trn_ki.loc[:,col_obj] = ki_obj.fit_transform(x_trn[col_obj])\n",
    "\n",
    "x_val_ki.loc[:,col_num] = ki_num.transform(x_val[col_num])\n",
    "x_val_ki.loc[:,col_obj] = ki_obj.transform(x_val[col_obj])\n",
    "\n",
    "x_tst_ki.loc[:,col_num] = ki_num.transform(x_tst[col_num])\n",
    "x_tst_ki.loc[:,col_obj] = ki_obj.transform(x_tst[col_obj])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Convert object columns into number format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le_si = LabelEncoder()\n",
    "le_ii = LabelEncoder()\n",
    "le_ki = LabelEncoder()\n",
    "le_y  = LabelEncoder()\n",
    "\n",
    "X_train_si = x_trn_si.copy()\n",
    "X_train_ii = x_trn_ii.copy()\n",
    "X_train_ki = x_trn_ki.copy()\n",
    "\n",
    "X_valid_si = x_val_si.copy()\n",
    "X_valid_ii = x_val_ii.copy()\n",
    "X_valid_ki = x_val_ki.copy()\n",
    "\n",
    "X_test_si  = x_tst_si.copy()\n",
    "X_test_ii  = x_tst_ii.copy()\n",
    "X_test_ki  = x_tst_ki.copy()\n",
    "\n",
    "for col in col_obj:\n",
    "    X_train_si.loc[:,col] = le_si.fit_transform(x_trn_si[col])\n",
    "    X_train_ii.loc[:,col] = le_ii.fit_transform(x_trn_ii[col])\n",
    "    X_train_ki.loc[:,col] = le_ki.fit_transform(x_trn_ki[col])\n",
    "    \n",
    "    X_valid_si.loc[:,col] = le_si.transform(x_val_si[col])\n",
    "    X_valid_ii.loc[:,col] = le_ii.transform(x_val_ii[col])\n",
    "    X_valid_ki.loc[:,col] = le_ki.transform(x_val_ki[col])\n",
    "    \n",
    "    X_test_si.loc[:,col] = le_si.transform(x_tst_si[col])\n",
    "    X_test_ii.loc[:,col] = le_ii.transform(x_tst_ii[col])\n",
    "    X_test_ki.loc[:,col] = le_ki.transform(x_tst_ki[col])\n",
    "    \n",
    "y_train = le_y.fit_transform(y_trn)\n",
    "y_valid = le_y.transform(y_val)\n",
    "y_test  = le_y.transform(y_tst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. SVM model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mike\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\svm\\_base.py:258: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Mike\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\svm\\_base.py:258: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Mike\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\svm\\_base.py:258: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Classification\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Polynomial with max degree of 4 and One-vs-Rest\n",
    "svc_model = SVC(C=0.5, kernel='poly', degree=4, coef0=0, tol=0.5, max_iter=300, decision_function_shape='ovr')\n",
    "\n",
    "svc_model.fit(X_train_si, y_train)\n",
    "svc_model.fit(X_train_ii, y_train)\n",
    "svc_model.fit(X_train_ki, y_train)\n",
    "\n",
    "y_train_si_pred = svc_model.predict(X_train_si)\n",
    "y_train_ii_pred = svc_model.predict(X_train_ii)\n",
    "y_train_ki_pred = svc_model.predict(X_train_ki)\n",
    "y_valid_si_pred = svc_model.predict(X_valid_si)\n",
    "y_valid_ii_pred = svc_model.predict(X_valid_ii)\n",
    "y_valid_ki_pred = svc_model.predict(X_valid_ki)\n",
    "y_test_si_pred = svc_model.predict(X_test_si)\n",
    "y_test_ii_pred = svc_model.predict(X_test_ii)\n",
    "y_test_ki_pred = svc_model.predict(X_test_ki)\n",
    "\n",
    "score_train_si = mean_absolute_error(y_train, y_train_si_pred)\n",
    "score_train_ii = mean_absolute_error(y_train, y_train_ii_pred)\n",
    "score_train_ki = mean_absolute_error(y_train, y_train_ki_pred)\n",
    "\n",
    "score_valid_si = mean_absolute_error(y_valid, y_valid_si_pred)\n",
    "score_valid_ii = mean_absolute_error(y_valid, y_valid_ii_pred)\n",
    "score_valid_ki = mean_absolute_error(y_valid, y_valid_ki_pred)\n",
    "\n",
    "score_test_si = mean_absolute_error(y_test, y_test_si_pred)\n",
    "score_test_ii = mean_absolute_error(y_test, y_test_ii_pred)\n",
    "score_test_ki = mean_absolute_error(y_test, y_test_ki_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score_train_si= 0.6725077653402098\n",
      "score_train_ii= 0.6720037508058372\n",
      "score_train_ki= 0.6714645724667408\n",
      "score_valid_si= 0.6744259643447379\n",
      "score_valid_ii= 0.673968845599353\n",
      "score_valid_ki= 0.673652378775625\n",
      "score_test_si= 0.6706283624600021\n",
      "score_test_ii= 0.6701009177537888\n",
      "score_test_ki= 0.6700657547733746\n"
     ]
    }
   ],
   "source": [
    "print('score_train_si=', score_train_si)\n",
    "print('score_train_ii=', score_train_ii)\n",
    "print('score_train_ki=', score_train_ki)\n",
    "print('score_valid_si=', score_valid_si)\n",
    "print('score_valid_ii=', score_valid_ii)\n",
    "print('score_valid_ki=', score_valid_ki)\n",
    "print('score_test_si=', score_test_si)\n",
    "print('score_test_ii=', score_test_ii)\n",
    "print('score_test_ki=', score_test_ki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
